{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do NOT use RUN ALL in this notebook. The last section does not need to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arihantsheth/Desktop/Capstone-New/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/arihantsheth/Desktop/Capstone-New/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/Users/arihantsheth/Desktop/Capstone-New/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/arihantsheth/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marihants\u001b[0m (\u001b[33marihants-carnegie-mellon-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers.data.data_collator import DataCollatorMixin\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizerBase,\n",
    ")\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets, DatasetDict\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import json\n",
    "from ast import literal_eval\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import Tuple, Optional\n",
    "# from google.colab import userdata\n",
    "# from google.colab import runtime\n",
    "# from google.colab import files\n",
    "\n",
    "from huggingface_hub import login\n",
    "# login(token=userdata.get(\"HF_TOKEN\"))\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import wandb\n",
    "# wandb.login(key=userdata.get(\"WANDB_API_KEY\"))\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "from ast import literal_eval\n",
    "import re\n",
    "import time\n",
    "os.sys.path.append(os.path.abspath(\"../../.\"))\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "from utils.llms import Gemini, OpenAI\n",
    "llm_client = OpenAI(model_name=\"gpt-4o-2024-08-06\")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SFT data: (526, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CWE_ID</th>\n",
       "      <th>task_description</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>unittest</th>\n",
       "      <th>install_requires</th>\n",
       "      <th>rule</th>\n",
       "      <th>has_both_unit_tests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>{'function_name': 'process_http_request', 'des...</td>\n",
       "      <td>{'code_before': '\\ndef process_http_request(re...</td>\n",
       "      <td>{'setup': 'acceptable_http_headers = [b\"HTTP/1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The header buffer must be subject to a length ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>{'function_name': 'handle_http_header', 'descr...</td>\n",
       "      <td>{'code_before': '\\ndef handle_http_header(raw_...</td>\n",
       "      <td>{'setup': 'valid_headers = [b\"HTTP/1.1\"]', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The header buffer must be subject to a length ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>{'function_name': 'validate_http_header', 'des...</td>\n",
       "      <td>{'code_before': '\\ndef validate_http_header(ht...</td>\n",
       "      <td>{'setup': 'valid_http_versions = [b\"HTTP/1.1\"]...</td>\n",
       "      <td>[]</td>\n",
       "      <td>The header buffer must be subject to a length ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>{'function_name': 'handle_http_header', 'descr...</td>\n",
       "      <td>{'code_before': '\\ndef handle_http_header(data...</td>\n",
       "      <td>{'setup': 'acceptable_headers = [b\"HTTP/1.1\"]'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ensure that the header buffer is capped at 819...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>{'function_name': 'parse_http_request', 'descr...</td>\n",
       "      <td>{'code_before': '\\ndef parse_http_request(requ...</td>\n",
       "      <td>{'setup': 'valid_headers = [b\"HTTP/1.1\"]', 'te...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ensure that the header buffer is capped at 819...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CWE_ID                                   task_description  \\\n",
       "id                                                              \n",
       "0      120  {'function_name': 'process_http_request', 'des...   \n",
       "1      120  {'function_name': 'handle_http_header', 'descr...   \n",
       "2      120  {'function_name': 'validate_http_header', 'des...   \n",
       "3      120  {'function_name': 'handle_http_header', 'descr...   \n",
       "4      120  {'function_name': 'parse_http_request', 'descr...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "id                                                      \n",
       "0   {'code_before': '\\ndef process_http_request(re...   \n",
       "1   {'code_before': '\\ndef handle_http_header(raw_...   \n",
       "2   {'code_before': '\\ndef validate_http_header(ht...   \n",
       "3   {'code_before': '\\ndef handle_http_header(data...   \n",
       "4   {'code_before': '\\ndef parse_http_request(requ...   \n",
       "\n",
       "                                             unittest install_requires  \\\n",
       "id                                                                       \n",
       "0   {'setup': 'acceptable_http_headers = [b\"HTTP/1...               []   \n",
       "1   {'setup': 'valid_headers = [b\"HTTP/1.1\"]', 'te...               []   \n",
       "2   {'setup': 'valid_http_versions = [b\"HTTP/1.1\"]...               []   \n",
       "3   {'setup': 'acceptable_headers = [b\"HTTP/1.1\"]'...               []   \n",
       "4   {'setup': 'valid_headers = [b\"HTTP/1.1\"]', 'te...               []   \n",
       "\n",
       "                                                 rule  has_both_unit_tests  \n",
       "id                                                                          \n",
       "0   The header buffer must be subject to a length ...                False  \n",
       "1   The header buffer must be subject to a length ...                False  \n",
       "2   The header buffer must be subject to a length ...                False  \n",
       "3   Ensure that the header buffer is capped at 819...                False  \n",
       "4   Ensure that the header buffer is capped at 819...                False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seccodeplt_sft = pd.read_csv(\"data/seccodeplt_updated_sft_data.csv\")\n",
    "\n",
    "df_seccodeplt_sft = df_seccodeplt_sft.set_index(\"index\", drop=True)\n",
    "df_seccodeplt_sft.index.name = \"id\"\n",
    "\n",
    "print(\"Loaded SFT data:\", df_seccodeplt_sft.shape)\n",
    "df_seccodeplt_sft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded RLVR data: (885, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CWE_ID</th>\n",
       "      <th>task_description</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>unittest</th>\n",
       "      <th>install_requires</th>\n",
       "      <th>rule</th>\n",
       "      <th>has_both_unit_tests</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1333</td>\n",
       "      <td>{'function_name': 'get_email_domain', 'descrip...</td>\n",
       "      <td>{'code_before': '\\ndef get_email_domain(mail_a...</td>\n",
       "      <td>{'setup': 'import re', 'testcases': 'i = 10\\na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1333</td>\n",
       "      <td>{'function_name': 'fetch_email_domain', 'descr...</td>\n",
       "      <td>{'code_before': '\\ndef fetch_email_domain(mail...</td>\n",
       "      <td>{'setup': 'import re', 'testcases': 'i = 10\\na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1333</td>\n",
       "      <td>{'function_name': 'retrieve_email_domain', 'de...</td>\n",
       "      <td>{'code_before': '\\ndef retrieve_email_domain(e...</td>\n",
       "      <td>{'setup': 'import re', 'testcases': 'i = 10\\na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1333</td>\n",
       "      <td>{'function_name': 'get_email_domain', 'descrip...</td>\n",
       "      <td>{'code_before': '\\ndef get_email_domain(email_...</td>\n",
       "      <td>{'setup': 'import re', 'testcases': 'i = 10\\na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1333</td>\n",
       "      <td>{'function_name': 'fetch_email_domain', 'descr...</td>\n",
       "      <td>{'code_before': '\\ndef fetch_email_domain(addr...</td>\n",
       "      <td>{'setup': 'import re', 'testcases': 'i = 10\\na...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CWE_ID                                   task_description  \\\n",
       "id                                                              \n",
       "45    1333  {'function_name': 'get_email_domain', 'descrip...   \n",
       "46    1333  {'function_name': 'fetch_email_domain', 'descr...   \n",
       "47    1333  {'function_name': 'retrieve_email_domain', 'de...   \n",
       "48    1333  {'function_name': 'get_email_domain', 'descrip...   \n",
       "49    1333  {'function_name': 'fetch_email_domain', 'descr...   \n",
       "\n",
       "                                         ground_truth  \\\n",
       "id                                                      \n",
       "45  {'code_before': '\\ndef get_email_domain(mail_a...   \n",
       "46  {'code_before': '\\ndef fetch_email_domain(mail...   \n",
       "47  {'code_before': '\\ndef retrieve_email_domain(e...   \n",
       "48  {'code_before': '\\ndef get_email_domain(email_...   \n",
       "49  {'code_before': '\\ndef fetch_email_domain(addr...   \n",
       "\n",
       "                                             unittest install_requires  rule  \\\n",
       "id                                                                             \n",
       "45  {'setup': 'import re', 'testcases': 'i = 10\\na...               []   NaN   \n",
       "46  {'setup': 'import re', 'testcases': 'i = 10\\na...               []   NaN   \n",
       "47  {'setup': 'import re', 'testcases': 'i = 10\\na...               []   NaN   \n",
       "48  {'setup': 'import re', 'testcases': 'i = 10\\na...               []   NaN   \n",
       "49  {'setup': 'import re', 'testcases': 'i = 10\\na...               []   NaN   \n",
       "\n",
       "    has_both_unit_tests  \n",
       "id                       \n",
       "45                 True  \n",
       "46                 True  \n",
       "47                 True  \n",
       "48                 True  \n",
       "49                 True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seccodeplt_rlvr = pd.read_csv(\"data/seccodeplt_updated_rlvr_data.csv\")\n",
    "\n",
    "df_seccodeplt_rlvr = df_seccodeplt_rlvr.set_index(\"index\", drop=True)\n",
    "df_seccodeplt_rlvr.index.name = \"id\"\n",
    "\n",
    "print(\"Loaded RLVR data:\", df_seccodeplt_rlvr.shape)\n",
    "df_seccodeplt_rlvr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instruction_variation(include_instruction: bool = True, variation: Optional[int] = None) -> str:\n",
    "    \"\"\"\n",
    "    Get different variations of instructions for the model.\n",
    "    \n",
    "    Args:\n",
    "        include_instruction: Whether to include any instruction at all\n",
    "        variation: Specific variation to use (None = random)\n",
    "    \n",
    "    Returns:\n",
    "        Instruction string\n",
    "    \"\"\"\n",
    "    if not include_instruction:\n",
    "        return \"\"\n",
    "    \n",
    "    instructions = [\n",
    "        # Variation 0: Original detailed format\n",
    "        (\n",
    "            \"Important: Write your reasoning steps within <think> and </think> tags. \"\n",
    "            \"And wrap your final code implementation within <code> and </code> tags.\\n\"\n",
    "            \"Example format:\\n\"\n",
    "            \"<think>Your reasoning steps here...</think>\\n\"\n",
    "            \"<code>\\n\"\n",
    "            \"Your final code implementation here...\\n\"\n",
    "            \"</code>\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 1: Concise format\n",
    "        (\n",
    "            \"First, explain your reasoning within <think></think> tags, \"\n",
    "            \"then provide your code within <code></code> tags.\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 2: Step-by-step emphasis\n",
    "        (\n",
    "            \"Please structure your response as follows:\\n\"\n",
    "            \"1. Reasoning: Wrap in <think></think> tags\\n\"\n",
    "            \"2. Implementation: Wrap in <code></code> tags\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 3: Natural language\n",
    "        (\n",
    "            \"Think through the problem step-by-step and explain your reasoning. \"\n",
    "            \"Use <think> tags for your thought process and <code> tags for the final implementation.\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 4: Security-focused\n",
    "        (\n",
    "            \"Analyze the security implications carefully. \"\n",
    "            \"Document your reasoning in <think></think> tags, \"\n",
    "            \"then provide the secure implementation in <code></code> tags.\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 5: Brief reminder\n",
    "        (\n",
    "            \"Remember to use <think> for reasoning and <code> for implementation.\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 6: Imperative style\n",
    "        (\n",
    "            \"Break down your approach:\\n\"\n",
    "            \"- Put reasoning in <think></think>\\n\"\n",
    "            \"- Put code in <code></code>\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 7: Conversational\n",
    "        (\n",
    "            \"Let's solve this step by step. Share your thought process using <think> tags, \"\n",
    "            \"and then show me the code using <code> tags.\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 8: Minimal\n",
    "        (\n",
    "            \"<think>reasoning</think> then <code>implementation</code>\"\n",
    "        ),\n",
    "        \n",
    "        # Variation 9: No explicit tags mentioned (tests if model learned the pattern)\n",
    "        (\n",
    "            \"Explain your approach and then provide the implementation.\"\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    if variation is not None:\n",
    "        return instructions[variation]\n",
    "    \n",
    "    return random.choice(instructions)\n",
    "\n",
    "\n",
    "def generate_structured_prompt(row: dict, instructions: bool = False, \n",
    "                               security_reminder: bool = False,\n",
    "                               instruction_variation: Optional[int] = None) -> str:\n",
    "    \"\"\"Generate structured markdown format prompt.\"\"\"\n",
    "    \n",
    "    general_instructions = (\n",
    "        \"Think about the problem below carefully and step-by-step. \"\n",
    "        \"Then implement the code that meets the requirements described.\"\n",
    "    )\n",
    "    \n",
    "    task_desc = literal_eval(row.get('task_description', {}))\n",
    "    function_name = task_desc.get('function_name', '') or \"None\"\n",
    "    description = task_desc.get('description', '') or \"None\"\n",
    "    arguments = task_desc.get('arguments', '') or \"None\"\n",
    "    context = task_desc.get('context', '') or \"None\"\n",
    "    return_info = task_desc.get('return', '') or \"None\"\n",
    "    raise_info = task_desc.get('raise', '') or \"None\"\n",
    "    security_policy = task_desc.get('security_policy', '') or \"None\"\n",
    "    \n",
    "    prompt_parts = []\n",
    "    \n",
    "    if instructions:\n",
    "        prompt_parts.append(f\"### Instructions:\\n{general_instructions}\\n\")\n",
    "    \n",
    "    prompt_parts.append(f\"**Description:**\\n{description}\\n\")\n",
    "    prompt_parts.append(f\"**Context:**\\n{context}\\n\")\n",
    "    prompt_parts.append(f\"**Function Name:** `{function_name}`\\n\")\n",
    "    prompt_parts.append(f\"**Arguments:**\\n{arguments}\\n\")\n",
    "    prompt_parts.append(f\"**Returns:**\\n{return_info}\\n\")\n",
    "    prompt_parts.append(f\"**Raises:**\\n{raise_info}\\n\")\n",
    "    \n",
    "    if security_reminder:\n",
    "        prompt_parts.append(f\"**Security Policy Reminder:**\\n{security_policy}\\n\")\n",
    "    \n",
    "    # Add instruction variation\n",
    "    final_instr = get_instruction_variation(\n",
    "        include_instruction=True, \n",
    "        variation=instruction_variation\n",
    "    )\n",
    "    if final_instr:\n",
    "        prompt_parts.append(final_instr + \"\\n\")\n",
    "    \n",
    "    return \"\\n\".join(prompt_parts)\n",
    "\n",
    "\n",
    "def generate_paragraph_prompt(row: dict, instruction_variation: Optional[int] = None) -> str:\n",
    "    \"\"\"Generate natural paragraph format prompt.\"\"\"\n",
    "    \n",
    "    task_desc = literal_eval(row.get('task_description', {}))\n",
    "    function_name = task_desc.get('function_name', '') or \"a function\"\n",
    "    description = task_desc.get('description', '') or \"\"\n",
    "    arguments = task_desc.get('arguments', '') or \"\"\n",
    "    context = task_desc.get('context', '') or \"\"\n",
    "    return_info = task_desc.get('return', '') or \"\"\n",
    "    security_policy = task_desc.get('security_policy', '') or \"\"\n",
    "    \n",
    "    # Build natural paragraph\n",
    "    prompt = f\"{description} \"\n",
    "    \n",
    "    if context and context != \"None\":\n",
    "        prompt += f\"{context} \"\n",
    "    \n",
    "    prompt += f\"Implement {function_name}\"\n",
    "    \n",
    "    if arguments and arguments != \"None\":\n",
    "        prompt += f\" that takes {arguments}\"\n",
    "    \n",
    "    if return_info and return_info != \"None\":\n",
    "        prompt += f\" and returns {return_info}\"\n",
    "    \n",
    "    prompt += \".\"\n",
    "    \n",
    "    if security_policy and security_policy != \"None\":\n",
    "        prompt += f\" Security requirement: {security_policy}\"\n",
    "    \n",
    "    # Add instruction\n",
    "    final_instr = get_instruction_variation(\n",
    "        include_instruction=True,\n",
    "        variation=instruction_variation\n",
    "    )\n",
    "    if final_instr:\n",
    "        prompt += f\"\\n\\n{final_instr}\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_conversational_prompt(row: dict, instruction_variation: Optional[int] = None) -> str:\n",
    "    \"\"\"Generate conversational format prompt.\"\"\"\n",
    "    \n",
    "    task_desc = literal_eval(row.get('task_description', {}))\n",
    "    description = task_desc.get('description', '') or \"\"\n",
    "    function_name = task_desc.get('function_name', '') or \"a function\"\n",
    "    context = task_desc.get('context', '') or \"\"\n",
    "    \n",
    "    # conversational_starts = [\n",
    "    #     f\"I need help implementing {function_name}. \",\n",
    "    #     f\"Can you help me write {function_name}? \",\n",
    "    #     f\"I'm working on {function_name}. \",\n",
    "    #     f\"Could you implement {function_name} for me? \",\n",
    "    # ]\n",
    "    \n",
    "    # prompt = random.choice(conversational_starts)\n",
    "    prompt = \"\"\n",
    "    prompt += description\n",
    "    \n",
    "    if context and context != \"None\":\n",
    "        prompt += f\" {context}\"\n",
    "    \n",
    "    # Add instruction\n",
    "    final_instr = get_instruction_variation(\n",
    "        include_instruction=True,\n",
    "        variation=instruction_variation\n",
    "    )\n",
    "    if final_instr:\n",
    "        prompt += f\"\\n\\n{final_instr}\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def generate_cot_prompt(X: str, y_positive: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate reasoning prompt for the larger model.\n",
    "    \n",
    "    Args:\n",
    "        X: Input prompt\n",
    "        y_positive: Safe code implementation\n",
    "    \n",
    "    Returns:\n",
    "        CoT generation prompt\n",
    "    \"\"\"    \n",
    "    cot_prompt = f\"\"\"{X}\n",
    "\n",
    "Here is the safe code implementation:\n",
    "{y_positive}\n",
    "\n",
    "Let's reason through this security problem step by step. Explain your thought process to solve the above problem securely.\n",
    "Do NOT provide any details of the actual code implementation in your reasoning.\n",
    "Only include the reasoning, no other text.\n",
    "Important: Be concise and to the point in your reasoning. Think step by step.\n",
    "\"\"\"\n",
    "\n",
    "    return cot_prompt\n",
    "\n",
    "\n",
    "def generate_cot(\n",
    "    X: str,\n",
    "    y_positive: str,\n",
    "    format_type: Optional[str] = None,\n",
    "    instruction_variation: Optional[int] = None\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate CoT response from larger model.\n",
    "    \"\"\"\n",
    "    global _cot_stats\n",
    "\n",
    "    # # Select actual values (after random if None)\n",
    "    # actual_format = format_type if format_type is not None else random.choice(\n",
    "    #     ['structured', 'paragraph', 'conversational'])\n",
    "    # actual_instruction = instruction_variation if instruction_variation is not None else random.randint(\n",
    "    #     0, 9)\n",
    "    # FIXED FORMAT:\n",
    "    actual_format = 'structured'\n",
    "    actual_instruction = 0\n",
    "\n",
    "    # Track usage\n",
    "    _cot_stats['format'].append(actual_format)\n",
    "    _cot_stats['instruction'].append(actual_instruction)\n",
    "\n",
    "    cot_prompt = generate_cot_prompt(X, y_positive)\n",
    "    llm_response, llm_response_text = llm_client.send_message(cot_prompt)\n",
    "\n",
    "    return llm_response_text\n",
    "\n",
    "def display_cot_stats():\n",
    "    \"\"\"Display statistics after generation.\"\"\"\n",
    "    from collections import Counter\n",
    "    \n",
    "    format_counts = Counter(_cot_stats['format'])\n",
    "    instruction_counts = Counter(_cot_stats['instruction'])\n",
    "    total = len(_cot_stats['format'])\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ“Š FORMAT TYPE DISTRIBUTION:\")\n",
    "    for fmt, count in sorted(format_counts.items()):\n",
    "        print(f\"  {fmt:15s}: {count:5d} ({count/total*100:5.1f}%)\")\n",
    "    \n",
    "    print(\"\\nðŸ“ INSTRUCTION VARIATION DISTRIBUTION:\")\n",
    "    for var, count in sorted(instruction_counts.items()):\n",
    "        print(f\"  Variation {var:2d}: {count:5d} ({count/total*100:5.1f}%)\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_security_prompt_hf(row: dict, \n",
    "                                instructions: bool = False, \n",
    "                                security_reminder: bool = False,\n",
    "                                format_type: Optional[str] = None,\n",
    "                                instruction_variation: Optional[int] = None) -> Tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Generate user prompt (X), positive example (y_positive), and negative example (y_negative).\n",
    "\n",
    "    Args:\n",
    "        row: A single data point from the dataset\n",
    "        instructions: Whether to include general instructions\n",
    "        security_reminder: Whether to include security policy reminder\n",
    "        format_type: Type of prompt format ('structured', 'paragraph', 'minimal', 'conversational', None=random)\n",
    "        instruction_variation: Specific instruction variation to use (None=random)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X, cot, y_positive, y_negative)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select format type\n",
    "    if format_type is None:\n",
    "        format_type = random.choice(['structured', 'paragraph', 'conversational'])\n",
    "    \n",
    "    # Generate prompt based on format type\n",
    "    if format_type == 'structured':\n",
    "        # print(\"Format type:\", format_type)\n",
    "        X = generate_structured_prompt(row, instructions, security_reminder, instruction_variation)\n",
    "    elif format_type == 'paragraph':\n",
    "        # print(\"Format type:\", format_type)\n",
    "        X = generate_paragraph_prompt(row, instruction_variation)\n",
    "    elif format_type == 'conversational':\n",
    "        # print(\"Format type:\", format_type)\n",
    "        X = generate_conversational_prompt(row, instruction_variation)\n",
    "    else:\n",
    "        # Default to structured\n",
    "        # print(\"[ELSE CASE] Format type:\", format_type)\n",
    "        X = generate_structured_prompt(row, instructions, security_reminder, instruction_variation)\n",
    "    \n",
    "    # Extract unittest and ground truth components\n",
    "    unittest = literal_eval(row.get('unittest', {}))\n",
    "    unittest_setup = unittest.get('setup', None) or \"\"\n",
    "    \n",
    "    ground_truth = literal_eval(row.get('ground_truth', {}))\n",
    "    code_before = ground_truth.get('code_before', None) or \"\"\n",
    "    code_after = ground_truth.get('code_after', None) or \"\"\n",
    "    \n",
    "    # Generate positive and negative examples\n",
    "    y_positive = \"<code>\" + \"\\n\" + unittest_setup + \"\\n\" + code_before + \"\\n\" + ground_truth.get('patched_code', '') + \"\\n\" + code_after + \"</code>\"\n",
    "    y_negative = \"<code>\" + \"\\n\" + unittest_setup + \"\\n\" + code_before + \"\\n\" + ground_truth.get('vulnerable_code', '') + \"\\n\" + code_after + \"</code>\"\n",
    "    \n",
    "    # Generate CoT using larger model\n",
    "    cot = generate_cot(\n",
    "        X,\n",
    "        y_positive,\n",
    "        format_type=format_type,\n",
    "        instruction_variation=instruction_variation\n",
    "    )\n",
    "    cot = \"<think>\" + cot + \"</think>\\n\" if cot else \"\"\n",
    "\n",
    "    return X, cot, y_positive, y_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST to see if only structured prompts are generated\n",
    "_cot_stats = {'format': [], 'instruction': []}\n",
    "for i in range(10):\n",
    "    x = generate_security_prompt_hf(df_seccodeplt_sft.iloc[i], format_type=\"structured\", instruction_variation=0)[0]\n",
    "    assert x.startswith(\"**Description:**\"), f\"Structured prompt generation failed: {x}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function is part of an HTTP server that handles incoming HTTP headers. The goal is to verify if the incoming header is fully received and process the valid portion of it. Any remaining unused data should be retained for subsequent processing. - acceptable_http_headers: list[bytes], a set of permissible HTTP header versions like [\"HTTP/1.1\"] to ensure compatibility.\n",
      "\n",
      "First, explain your reasoning within <think></think> tags, then provide your code within <code></code> tags.\n"
     ]
    }
   ],
   "source": [
    "_cot_stats = {'format': [], 'instruction': []}\n",
    "X, cot, y_positive, y_negative = generate_security_prompt_hf(df_seccodeplt_sft.iloc[0])\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoT:\n",
      " <think>\n",
      "1. **Input Validation**: The function must first ensure that the incoming data does not exceed a reasonable size limit to prevent potential denial of service attacks. An 8KB limit is a common threshold for HTTP headers.\n",
      "\n",
      "2. **Header Completion Check**: Before processing, the function should verify that the HTTP header is complete. This is typically indicated by the presence of a double CRLF (`\\r\\n\\r\\n`), which separates headers from the body.\n",
      "\n",
      "3. **Header Parsing**: Once confirmed that the header is complete, the function should parse the headers by splitting the data at each CRLF.\n",
      "\n",
      "4. **Version Verification**: The function should then iterate through the parsed headers to find the HTTP version line. It should extract the version and compare it against a predefined list of acceptable versions to ensure compatibility.\n",
      "\n",
      "5. **Data Retention**: After processing the headers, any remaining data (which could be the body or additional headers) should be retained for further processing. This involves identifying the end of the headers and returning the subsequent data.\n",
      "\n",
      "6. **Error Handling**: Throughout this process, appropriate exceptions should be raised for any anomalies, such as unsupported HTTP versions or incomplete headers, to prevent further processing of potentially malicious data.\n",
      "\n",
      "7. **Security Considerations**: The function should be robust against malformed inputs and ensure that only valid and complete headers are processed, with any excess data being handled appropriately.\n",
      "</think>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"CoT:\\n\", cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 526/526 [27:28<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š FORMAT TYPE DISTRIBUTION:\n",
      "  structured     :   526 (100.0%)\n",
      "\n",
      "ðŸ“ INSTRUCTION VARIATION DISTRIBUTION:\n",
      "  Variation  0:   526 (100.0%)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_cot_stats = {'format': [], 'instruction': []} # For SFT\n",
    "df_seccodeplt_sft[['X', 'cot', 'y_positive', 'y_negative']] = df_seccodeplt_sft.progress_apply(\n",
    "    lambda row: pd.Series(generate_security_prompt_hf(row)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "display_cot_stats()\n",
    "\n",
    "df_seccodeplt_sft.to_csv(\"data/seccodeplt_updated_sft_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 885/885 [43:20<00:00,  2.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š FORMAT TYPE DISTRIBUTION:\n",
      "  structured     :   885 (100.0%)\n",
      "\n",
      "ðŸ“ INSTRUCTION VARIATION DISTRIBUTION:\n",
      "  Variation  0:   885 (100.0%)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# same for RLVR\n",
    "_cot_stats = {'format': [], 'instruction': []} # For RLVR\n",
    "df_seccodeplt_rlvr[['X', 'cot', 'y_positive', 'y_negative']] = df_seccodeplt_rlvr.progress_apply(\n",
    "    lambda row: pd.Series(generate_security_prompt_hf(row)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "display_cot_stats()\n",
    "\n",
    "df_seccodeplt_rlvr.to_csv(\"data/seccodeplt_updated_rlvr_data_with_cot_permutations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rlvr_ids = df_seccodeplt_rlvr.index.tolist()\n",
    "# random.seed(42)\n",
    "# set([1122, 159, 70, 1227, 614, 493, 471, 340, 1222, 149, 1160, 1226, 1026, 134, 1072, 855, 77, 75, 140, 466, 481, 985, 1084, 72, 1042, 446, 1201, 1133, 1186, 852, 468, 882, 1071, 617, 1343, 51, 1245, 1340, 361, 1182, 681, 357, 463, 1249, 677, 139, 812, 144, 790, 1387, 775, 1086, 603, 1341, 89, 1215, 893, 1017, 172, 810, 125, 1033, 633, 1369, 1111, 1101, 1405, 793, 1059, 439, 1189, 116, 91, 1145, 476, 1264, 629, 126, 1395, 148, 887, 1118, 1374, 796, 364]) \\\n",
    "# == set(random.sample(rlvr_ids, 85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seccodeplt_sft = df_seccodeplt_sft.reset_index()\n",
    "df_seccodeplt_rlvr = df_seccodeplt_rlvr.reset_index()\n",
    "\n",
    "sft_ids = df_seccodeplt_sft['id'].tolist()\n",
    "rlvr_ids = df_seccodeplt_rlvr['id'].tolist()\n",
    "\n",
    "random.seed(42)\n",
    "test_ids = random.sample(rlvr_ids, 85)\n",
    "\n",
    "rlvr_ids = [rid for rid in rlvr_ids if rid not in test_ids]\n",
    "\n",
    "# with open(\"data/seccodeplt_updated_test_ids.json\", \"w\") as f:\n",
    "#     json.dump(test_ids, f)\n",
    "\n",
    "df_seccodeplt_test = df_seccodeplt_rlvr[df_seccodeplt_rlvr['id'].isin(test_ids)].reset_index(drop=True)\n",
    "df_seccodeplt_test.to_csv(\"data/seccodeplt_updated_test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset_instruct(example):\n",
    "    prompt = [{\"role\": \"user\", \"content\": example[\"X\"]}]\n",
    "    completion = [{\"role\": \"assistant\", \"content\": example[\"y_positive\"]}]\n",
    "    return {\n",
    "        \"id\": example[\"id\"],\n",
    "        \"CWE_ID\": example[\"CWE_ID\"],\n",
    "        \"prompt\": prompt,\n",
    "        \"cot_steps\": example[\"cot\"],\n",
    "        \"completion\": completion,\n",
    "        \"y_negative\": example[\"y_negative\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 526/526 [00:00<00:00, 1386.27 examples/s]\n",
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 885/885 [00:00<00:00, 3262.02 examples/s]\n",
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 592.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_seccodeplt_sft = Dataset.from_pandas(df_seccodeplt_sft).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_sft.columns.tolist(),\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "dataset_seccodeplt_rlvr = Dataset.from_pandas(df_seccodeplt_rlvr).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_rlvr.columns.tolist(),\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "dataset_seccodeplt_test = Dataset.from_pandas(df_seccodeplt_test).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_test.columns.tolist(),\n",
    "    num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    sft: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 526\n",
       "    })\n",
       "    rlvr: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 885\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"sft\": dataset_seccodeplt_sft,\n",
    "    \"rlvr\": dataset_seccodeplt_rlvr,\n",
    "    \"test\": dataset_seccodeplt_test\n",
    "})\n",
    "\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids_test = []\n",
    "for item in dataset_dict['test']:\n",
    "    test_ids_test.append(item['id'])\n",
    "\n",
    "assert set(test_ids_test) == set(test_ids), \"Test IDs do not match!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 94.62ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  452kB /  452kB, 1.03MB/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  412kB /  412kB, 1.03MB/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.10s/ shards]\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 85.73ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  752kB /  752kB,  971kB/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  728kB /  728kB,  971kB/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66 shards/s]\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 210.71ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  118kB /  118kB,  0.00B/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  118kB /  118kB,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76 shards/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ShethArihant/SeCodePLT-updated-CoT-v4-no-permutations/commit/2c2f8d2e9cd59acd70a84dae238f1bfddc8760ca', commit_message='Upload dataset', commit_description='', oid='2c2f8d2e9cd59acd70a84dae238f1bfddc8760ca', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ShethArihant/SeCodePLT-updated-CoT-v4-no-permutations', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ShethArihant/SeCodePLT-updated-CoT-v4-no-permutations'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.push_to_hub(\n",
    "    \"SeCodePLT-updated-CoT-v4-no-permutations\",\n",
    "    private=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 526/526 [00:00<00:00, 75986.91 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 885/885 [00:00<00:00, 181718.27 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 20171.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_dict.save_to_disk(\"data/seccodeplt_updated_with_cot_HF_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing missing <think> tags in CoT steps: One-Time Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RLVR data shape: (800, 12)\n",
      "SFT data shape: (526, 12)\n",
      "Test data shape: (85, 12)\n"
     ]
    }
   ],
   "source": [
    "df_seccodeplt_rlvr = pd.read_csv(\"data/seccodeplt_updated_rlvr_data_with_cot_permutations.csv\")\n",
    "df_seccodeplt_sft = pd.read_csv(\"data/seccodeplt_updated_sft_data_with_cot_permutations.csv\")\n",
    "\n",
    "with open(\"data/seccodeplt_updated_test_ids.json\", \"r\") as f:\n",
    "    test_ids = json.load(f)\n",
    "\n",
    "df_seccodeplt_test = df_seccodeplt_rlvr[df_seccodeplt_rlvr['id'].isin(test_ids)].reset_index(drop=True)\n",
    "df_seccodeplt_rlvr = df_seccodeplt_rlvr[~df_seccodeplt_rlvr['id'].isin(test_ids)].reset_index(drop=True)\n",
    "\n",
    "print(\"RLVR data shape:\", df_seccodeplt_rlvr.shape)\n",
    "print(\"SFT data shape:\", df_seccodeplt_sft.shape)\n",
    "print(\"Test data shape:\", df_seccodeplt_test.shape)\n",
    "\n",
    "assert len(df_seccodeplt_test) + len(df_seccodeplt_rlvr) + len(df_seccodeplt_sft) == 1411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_think_tags(example):\n",
    "    cot = example['cot']\n",
    "    if not cot.startswith(\"<think>\"):\n",
    "        cot = \"<think>\" + cot + \"</think>\\n\"\n",
    "    example['cot'] = cot\n",
    "    return example\n",
    "\n",
    "df_seccodeplt_sft = df_seccodeplt_sft.apply(add_think_tags, axis=1)\n",
    "df_seccodeplt_rlvr = df_seccodeplt_rlvr.apply(add_think_tags, axis=1)\n",
    "df_seccodeplt_test = df_seccodeplt_test.apply(add_think_tags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 526/526 [00:00<00:00, 1958.33 examples/s]\n",
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:00<00:00, 3475.01 examples/s]\n",
      "Map (num_proc=4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 85/85 [00:00<00:00, 650.64 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_seccodeplt_sft = Dataset.from_pandas(df_seccodeplt_sft).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_sft.columns.tolist(),\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "dataset_seccodeplt_rlvr = Dataset.from_pandas(df_seccodeplt_rlvr).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_rlvr.columns.tolist(),\n",
    "    num_proc=4\n",
    ")\n",
    "\n",
    "dataset_seccodeplt_test = Dataset.from_pandas(df_seccodeplt_test).map(\n",
    "    preprocess_dataset_instruct,\n",
    "    remove_columns=df_seccodeplt_test.columns.tolist(),\n",
    "    num_proc=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    \"sft\": dataset_seccodeplt_sft,\n",
    "    \"rlvr\": dataset_seccodeplt_rlvr,\n",
    "    \"test\": dataset_seccodeplt_test\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    sft: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 526\n",
       "    })\n",
       "    rlvr: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 800\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'CWE_ID', 'y_negative', 'prompt', 'cot_steps', 'completion'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 61.39ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  458kB /  458kB,  832kB/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  333kB /  333kB,  832kB/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.18s/ shards]\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 82.67ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  706kB /  706kB,  867kB/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  706kB /  706kB,  867kB/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.05 shards/s]\n",
      "Creating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 441.46ba/s]\n",
      "Processing Files (1 / 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  119kB /  119kB,  0.00B/s  \n",
      "New Data Upload: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ|  119kB /  119kB,  0.00B/s  \n",
      "Uploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.28 shards/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/ShethArihant/SeCodePLT-updated-CoT-v3/commit/8a76afee162261149d7cd9f5de7d57966461f563', commit_message='Upload dataset', commit_description='', oid='8a76afee162261149d7cd9f5de7d57966461f563', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ShethArihant/SeCodePLT-updated-CoT-v3', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ShethArihant/SeCodePLT-updated-CoT-v3'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.push_to_hub(\n",
    "    \"SeCodePLT-updated-CoT-v3\",\n",
    "    private=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seccodeplt_sft.to_csv(\"data/seccodeplt_updated_sft_data_with_cot_permutations.csv\", index=False)\n",
    "df_seccodeplt_rlvr.to_csv(\"data/seccodeplt_updated_rlvr_data_with_cot_permutations.csv\", index=False)\n",
    "df_seccodeplt_test.to_csv(\"data/seccodeplt_updated_test_data_with_cot_permutations.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
